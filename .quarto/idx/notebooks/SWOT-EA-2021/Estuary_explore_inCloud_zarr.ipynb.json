{"title":"Use Case: Study Amazon Estuaries with Data from the EOSDIS Cloud","markdown":{"headingText":"Use Case: Study Amazon Estuaries with Data from the EOSDIS Cloud","containsRefs":false,"markdown":"\n\n<img src=\"https://cdn.earthdata.nasa.gov/conduit/upload/12946/EOSDISCloud-logo.jpg\" width=\"45%\" />\n\n<p><left>Read more about the EOSDIS Cloud at <a href=\"https://earthdata.nasa.gov/eosdis/cloud-evolution\" >NASA Earthdata</a>.</center></p>\n\n## Overview\n\nThis tutorial uses satellite data products to analyze the relationships between river height and land water equivalent thickness in the Amazon River estuary. Users can expand on these examples to also include sea surface salinity, sea surface temperature, and ocean color for example, for a more comprehensive exploration of the Amazon river basin's estuary and coastal region.\nThe contents are useful for the ocean, coastal and terrestrial hydrosphere disciplines, showcasing how to use on premises and Earthdata cloud datasets, existing Earthdata cloud services and functionalities, and Earthdata User Interface (UI) and Application Programming Interfaces (API).\n\n### Learning objectives:\n\n* Search for land water equivalent (LWE) thickness (GRACE/GRACE-FO) and river discharge data (MEaSUREs Pre-SWOT)\n* Access LWE thickeness dataset in Zarr format from Earthdata Cloud (AWS) using the Harmony API (specifically the Zarr reformatted service)\n* Access discharge dataset from PODAAC on premise (server) data archive\n* Subset both, plot and compare coincident data.\n\n### Datasets\n\nThe tutorial uses a combination of cloud and on premises datasets:\n- [**JPL GRACE and GRACE-FO Mascon Ocean, Ice, and Hydrology Equivalent Water Height Coastal Resolution Improvement (CRI) Filtered Release 06 Version 02**](https://podaac.jpl.nasa.gov/dataset/TELLUS_GRAC-GRFO_MASCON_CRI_GRID_RL06_V2)\n    - Provides land water equivalent (LWE) thickness for observing seasonal changes in water storage around the river. When discharge is high, the change in water storage will increase, pointing to a wet season. Source data are from [GRACE](https://podaac.jpl.nasa.gov/GRACE) and [GRACE-FO](https://podaac.jpl.nasa.gov/GRACE-FO).\n- [**Pre SWOT Hydrology GRRATS Daily River Heights and Storage Version 2**](https://podaac.jpl.nasa.gov/dataset/PRESWOT_HYDRO_GRRATS_L2_DAILY_VIRTUAL_STATION_HEIGHTS_V2)\n    - Provides virtual gauges to stand in for discharge data from Surface Water and Ocean Topography (SWOT). MEaSUREs contains river height products, not discharge, but river height is directly related to discharge and thus will act as a good substitute. Data were produced for the [Pre-SWOT Making Earth System Data Records for Use in Research Environments (MEaSUREs)](https://podaac.jpl.nasa.gov/MEaSUREs-Pre-SWOT) Program.\n\n## Requirements\n\nThis notebook was developed to run in the AWS cloud (us-west-2 region), next to the Earthdata Cloud (PO.DAAC) data holdings, to leverage cloud optimized data formats (e.g. Zarr) and the Earthdata Harmony API, specifically the Zarr refomrating service. For more informaion on Harmony, please see https://harmony.earthdata.nasa.gov/ .\n\n### Before you start\n\nBefore you beginning this tutorial, make sure you have an account in the Earthdata Login, which is required to access data from the NASA Earthdata system. Please visit https://urs.earthdata.nasa.gov to register for an Earthdata Login account. It is free to create and only takes a moment to set up.\n\nYou will also need a netrc file containing your NASA Earthdata Login credentials in order to execute this notebook. A netrc file can be created manually within text editor and saved to your home directory. For additional information see: [Authentication for NASA Earthdata](https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/04_NASA_Earthdata_Authentication.html#authentication-via-netrc-file).\n\nIn this notebook, we will be calling the authentication in the below cell, a work around if you do not yet have a netrc file.\n\nThis notebook was developed in Python 3.6.\n\n### Endpoints\n\nSet a few endpoints for use during the remainder of the workflow:\n\n## Cloud data from JPL GRACE and GRACE-FO Mascon\n\n![grace mascon](https://podaac.jpl.nasa.gov/Podaac/thumbnails/TELLUS_GRAC-GRFO_MASCON_CRI_GRID_RL06_V2.jpg)\n\n**JPL GRACE and GRACE-FO Mascon Ocean, Ice, and Hydrology Equivalent Water Height Coastal Resolution Improvement (CRI) Filtered Release 06 Version 02**\n\nThis dataset contains gridded monthly global water storage/height anomalies relative to a time-mean, derived from GRACE and GRACE-FO and processed at JPL using the Mascon approach (Version2/RL06). These data are provided in a single data file in netCDF format, and can be used for analysis for ocean, ice, and hydrology phenomena. This version of the data employs a Coastal Resolution Improvement (CRI) filter that reduces signal leakage errors across coastlines. The water storage/height anomalies are given in equivalent water thickness units (cm). The solution provided here is derived from solving for monthly gravity field variations in terms of geolocated spherical cap mass concentration functions, rather than global spherical harmonic coefficients. Additionally, realistic geophysical information is introduced during the solution inversion to intrinsically remove correlated error. Thus, these Mascon grids do not need to be destriped or smoothed, like traditional spherical harmonic gravity solutions. The complete Mascon solution consists of 4,551 relatively independent estimates of surface mass change that have been derived using an equal-area 3-degree grid of individual mascons. A subset of these individual mascons span coastlines, and contain mixed land and ocean mass change signals. \n\nFor more information, please visit https://grace.jpl.nasa.gov/data/get-data/jpl_global_mascons/. \n\nFor a detailed description on the Mascon solution, including the mathematical derivation, implementation of geophysical constraints, and solution validation, please see Watkins et al., 2015, doi: 10.1002/2014JB011547. For a detailed description of the CRI filter implementation, please see Wiese et al., 2016, doi: 10.1002/2016WR019344.\n\n### Metadata\n\nData from the [TELLUS_GRAC-GRFO_MASCON_CRI_GRID_RL06_V2](https://podaac.jpl.nasa.gov/dataset/TELLUS_GRAC-GRFO_MASCON_CRI_GRID_RL06_V2) dataset can be obtained from AWS S3. Use its *ShortName* to retrieve the *collection* metadata from CMR:\n\n#### Collection (dataset)\n\nGet the UMM Collection metadata using `requests.get`:\n\nThere should be only one result. Select and print its CMR Search metadata:\n\n#### Granule (file)\n\nGet the UMM Granule metadata using `requests.get`:\n\nAs you can see, one result was returned (one *hit*). Print the CMR Search metadata for the granule (`meta`):\n\nThe other component in each result (from the list of `items`) is the UMM metadata, accessible from the `umm` key. Print the *RelatedUrls* metadata field for the granule:\n\nWe want the URL corresponding to `'Type': 'GET DATA'`. Select the URL from appropriate item in the list, then print:\n\nThen, to do a regular HTTPS download:\n    \n```python\nr = requests.get(grace_url)\nwith open('tutorial7_data_GRACEFO.nc', 'wb') as f:\n    f.write(r.content)\n\n!ncdump -h tutorial7_data_GRACEFO.nc\n```\n\nBut we'll use the Harmony API's Zarr Reformatter service instead of downloading the entire granule. The zarr format will allow us to open and download/read just the data that we require for our Amazon Basin study area.\n\n### Request to Harmony API: Zarr Reformatter \n\nIf you have a `jobID` you'd like to re-visit instead of running this command again, modify the cell below to set the *async_jobId* then skip to `Format and display the complete url to the Harmony API job:`.\n\n*If you are running for the first time, proceed to the next cells to submit the harmony request.*\n\n*See important usage note below if this is your first time submitting a request to the Zarr Reformatter service.*\n\nThe Zarr Reformatter service operates on an input Collection *concept-id* (a CMR construct). The service will accept more user-friendly inputs (like a Collection *ShortName*) in future releases. Here's how you identify the CMR *concept-id* for the JPL GRACE/GRACE-FO Mascon dataset:\n\nMost of this next cell will only evaluate if there's NOT a valid job identifier set to the `async_jobId` variable above. It submits the Harmony request, and prints the JSON response.\n\nQuery for the job status and links in case the request is still processing:\n\n**Access url for the output zarr file**\n\nThe new zarr dataset is staged for us in an S3 bucket. The url is the second to last one in the list shown above.\n\nSelect the url and display below:\n\n**Access credentials for the output zarr file**\n\nCredentials provided at the third and fourth urls in the list grant authenticated access to your staged S3 resources.\n\nGrab the credentials as a JSON string, load to a Python dictionary, and display their expiration date:\n\n### Open staged zarr file with *s3fs*\n\nWe use the AWS `s3fs` package to get metadata about the zarr data store and list its contents:\n\nNow print metadata for the *lwe_thickness* variable:\n\n### Open staged zarr file with *xarray*\n\nHere's the documentation for `xarray`'s zarr reader: http://xarray.pydata.org/en/stable/generated/xarray.open_zarr.html\n\nOpen the zarr dataset and print the dataset:\n\n**Subset by Latitude/Longitude**\n\nOnce we have obtained all the data, to make processing quicker, we are going to subset datasets by latitude/longitude for the Amazon River estuary.\n\nOnce we have obtained the GRACE-FO data, we should spatial subset the data to the minimal area covering the Amazon River estuary. This will reduce processing load and reduce cloud costs for the user.\n\nMake a GRACE-FO subset and display the min, max of the *lat* and *lon* variables:\n\n**Select the variable for Land Water Equivalent Thickness (*lwe_thickness*)**\n\nGrab the land water equivalent thickness variable from the GRACE subset:\n\n### Plots\n\nWe will create an animation from sequential GRACE-FO plots over the Amazon Rainforest in the following cells. Define two functions to make the process a bit more convenient:\n\nPlot the first timestep in the JPL GRACE/GRACE-FO Mascon time series:\n\nPlot all the 2019 timesteps sequentially to create an animation of land water equivalent thickness for the Amazon Rainforest territories:\n\nUser note: You will need to install 'ffmpeg' in the cmd prompt to save the .mpg to disk. Use the following command to install from the conda-forge channel:\n\n```shell\nconda install -c conda-forge ffmpeg\n```\n\nUncomment, run the next cell to save the animation to MP4:\n\n## On-prem hydro data from Pre-SWOT MEaSUREs program\n\nData from [**PRESWOT_HYDRO_GRRATS_L2_DAILY_VIRTUAL_STATION_HEIGHTS_V2**](https://podaac.jpl.nasa.gov/dataset/PRESWOT_HYDRO_GRRATS_L2_DAILY_VIRTUAL_STATION_HEIGHTS_V2) are not currently available on the cloud, but we can access via the PO.DAAC's on-prem OPeNDAP service (Hyrax) instead.\n\n<img src=\"https://podaac.jpl.nasa.gov/Podaac/thumbnails/PRESWOT_HYDRO_GRRATS_L2_DAILY_VIRTUAL_STATION_HEIGHTS_V2.jpg\" width=\"55%\">\n\nThe guidebook explains the details of the Pre-SWOT MEaSUREs data: https://podaac-tools.jpl.nasa.gov/drive/files/allData/preswot_hydrology/L2/rivers/docs/GRRATS_user_handbookV2.pdf\n\n**Access URL for PO.DAAC on-prem OPeNDAP service**\n\nIdentify an appropriate OPeNDAP endpoint through the following steps:\n\n1. Go to the project/mission page on the PO.DAAC portal (e.g. for Pre-SWOT MEaSUREs: https://podaac.jpl.nasa.gov/MEaSUREs-Pre-SWOT)\n\n2. Choose the dataset of interest. Go to the \"Data Access\" tab of the corresponding dataset landing page, which should like the OPeNDAP access link (for compatible datasets, e.g. for the daily river heights from virtual stations: https://podaac-opendap.jpl.nasa.gov/opendap/allData/preswot_hydrology/L2/rivers/daily/).\n\n3. Navigate to the desired NetCDF file and copy the endpoint (e.g. for our Amazon Basin use case we choose the South America file: https://opendap.jpl.nasa.gov/opendap/allData/preswot_hydrology/L2/rivers/daily/South_America_Amazon1kmdaily.nc).\n\n### Open netCDF file with *xarray*\n\nOpen the netCDF dataset via OPeNDAP using *xarray*:\n\nOur desired variable is height (meters above EGM2008 geoid) for this exercise, which can be subset by distance and time. Distance represents the distance from the river mouth, in this example, the Amazon estuary. Time is between April 8, 1993 and April 20, 2019.\n\n### Plot\n\n**Amazon River heights for March 16, 2018**\n\nPlot the river distances and associated heights on the map at time t=9069:\n\nFor GRACE-FO, plotting lwe_thickness[107:179,34,69] indicates time, latitude, and longitude indices corresponding to the pixel for the time period 1/2019 to 12/2019 at lat/lon (-0.7, -50). For the 2019 year, measurements of LWE thickness followd expected patterns of high volume of water from the river output into the estuary.\n\n**2011-2019 Seasonality Plots (WIP)**\n\nFor GRACE-FO, plotting lwe_thickness[107:179,34,69] indicates time, latitude, and longitude indices corresponding to the pixel for the time period 8/2011 to 12/2019 at lat/lon (-0.7, -50).\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["../../include-files.lua","quarto"],"toc":true,"output-file":"Estuary_explore_inCloud_zarr.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","theme":{"light":"cosmo","dark":"darkly"},"code-copy":true},"extensions":{"book":{"multiFile":true}}}}}